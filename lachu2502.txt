import numpy as np # scientific computation
import pandas as pd # loading dataset file
import matplotlib.pyplot as plt # visulization
import nltk # preprocessing our text
from nltk.corpus import stopwords # removing all the stop words 
from nltk.stem.porter import porterstemer # stemming of words

#Load our dataset 
df=pd.read_csv("spam.csv",encoding="latin")
df.head()

#Give concise summary of a data 
df.info()

#Returns the sum fo all na values
df.isna().sum()
df.rename({"V1:"lable","V2":text"},inplace=True,axis=1
#botton 5 rows of the dataframe
df.tail()

fromsklear.preprocessing import LableEncode
le=LableEncoder()
df['lable']=le.fit_transform(df['lable'])

#splitting data into train and validation sets using train_test_split

from sklearn.model_selection import train_test_split
X_train,X_test,Y_test=train_test_spilt(X,Y,test_size=0.20,random_state=0)

##train size 80% and test size 20%

print("Before oversampling,counts of lable'1':{}".format(sum(y_train==)))
print("Before oversampling,counts of lable'0':{}\n".format(sum(y_train==0)))

#import SMOTE module from imblearn library
#pip install imblearn(if you don't have imblearn in your system )
from imblearn.over_sampling import SMOTE
sm=SMOTE(random_state = 2)
X_train_res,y_train_res = sm.fit_resample(x_train,y_train.ravel())
 
print("After oversampling,the shape of train_x:{}'.format(x_train_res.shape))
print("After oversampling,the shape of train_y:{}\n.format(y_train_res.shape))

print("After oversampling,the counts of lable '1':{}".format(sum(y_train_res==1)))
print("After oversampling,the counts of lable '0':{}".format(sum(y_train_res==0)))


import nltk
from nltk.corpus import stopwords
from nltk.stem import porterstemmer

import re
corpus = []
length = len(df)

for i in range(0,length):
text = re.sub("[a-ZA-Z0-9]"," ",df["text"][i])
text = text.lower()
text = text.split()
pe = porterstemmer()
stopword = stopwords.words("english")
text = [pe.stem(word) for word in text if not word in set(stopword)]
text = " ".join(text)
corpus.append(text)


import pickle ##importing pickle used for dumpimg models
pickle.dump(cv,open('cv1.pk1','wb')) ## saving to into cv.pkl file


df["lable"].value_counts().plot(kind="bar",figsize=(12,6))
plt.xticks(np.arange(2), ('Non spam','spam'),rotation=0);


#splitting data into train and validation sets using train_test_split


from sklearn,model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x, y, test_size=0.20,random_state=0)
 

##train sixe 80% and test size 20%


from sklearn.tree import DecisionTreeClassifier
model = DecisionTreeClassifier()
model.fit(X_train_res,y_train_res)
DecisionTreeClassifier
DecisionTreeClassifier()

from sklearn.ensemble import RandomForestClassifier
model1 =RandomForestClassifier()
model1,fit(x_train_res,y_train_res)
 RandomForestClassifier
RandomForestClassifier()


from sklearn.naive_bayes import MultinomialNB
modelv = MultinomialNB()
#Fitting the model to the training sets
model.fit(x_train_res,y_train_res)
 MultinomialNB
MulinomialNB()

from tensorflow.keras,models import sequential
from tensorflow.keras,layers import Dense
#Fitting the model to the training sets 
model = Sequential

 from sklearn.matrics import confusion_matrix,accuracy_score
cm = confusion_matrix(y_test,y_pr)
score = accuracy_score(y_test,y_pr)
print(cm)
print('Accuracy score Is:- ' ,score*100)


def new_review(new_review):
  new_review = new_review
  new_review = re.sub('[^a-ZA-Z]', ' ',new_review) 
  new_review = new_review.lower()
  new_review = new_review.split()
  ps = porterstemmer()
  all_stopwords = stopwords.)words('english')
  all_stopwords.remove('not')
  new_review = [ps,stem(word) for word 1n new_review 1f not word 1n  set(all_stopwords)]
  new_review = '.join(new_review)
  new_corpus = [new_review]
  new_x_test = cv.transform(new_corpus).toarray()
  print(new_x_test)
  new_y_pred = loaded_model.predict(new_x_)
  print(new_y_pred)
  new_x_pred = npp.where(new_y_pred>0.5,1,0)
  return new_y_pred
new_review = new_review(str(input("Enter new review ...")))


from sklearn.metrics import confusion_matrix,accuracy_score,classification_report
cm = confusion_matrix(y_test,y_pred)
score = accuracy_score(y_test,y_pred)
print(cm)
print('Accuracy score Is Naive Byes:- '  ,score*100)
 
cm = confusion_matrix(y_-test,y-pred)
score = accuracy_score(y_test,y_pred)
print(cm)
print('Accuracy score Is:-' ,score*100)
 
cm1 = confusion_matrix(y_test,y_pred)
score1 = accuracy_score(y-test,y_pred)
print(cm1)
print('Accuracy score Is:-'  ,score1*100)


from sklearn.metrics import confusion_matrix,accuracy_score
cm = confusion_matrix(y_test,y_pr)
score = accuracy_score(y_test,y_pr)
print(cm)
print('Accuracy score Is:- '  ,score*100)

from sklearn.matrics import confusion_matrix,accuracy_score
cm = confusion_matrix(y_test,y_pr)
score = accuracy_score(y_test,y_pr)
print(cm)
print('Accuracy score Is:- '  ,score*100)


#Importing essential libraries

from flask import Flask,render_template,request
import pickle
import numpy as np
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import porterstemmer
from tensorflow.keras.models import load_model

#Load the Multinomial Naive Bayes model and countvector


#Load the Multinomial Naive Bayes model
loaded_model=load_model1('spam.h5'')
cv = pickle.load(open('cv1.pkl',,'rb'))
app = Flask(__name__)

@app.route('/')# rendering the html template
def home():
    return render_template('home.html')


@app.route('/spam',methods=['POST','GET'])
def prediction(): # route which will take you to the prediction page
    return render_template('spam.html')

@app.route('/predict',methods=['POST'])
def predict():
    if request.method == 'POST':
        message = request.form['message']
        data = message
    
    new_review =str(date)
    print(new_review)
    new_review = re.sub('[^a-ZA-Z]', ' ', new_review
    new_review = new_review.lower()
    new_review = new_review.split()
    ps = porterstemmer()
    all_stopwords = stopwords.words('english')
    all_stopwords.remove('not')
    new_review = [[ps.stem(word) for word in new_review if not word in  set(all_stopwords)]
    new_review = ' '.join(new-review)
    new_corpus = [new_review]
    new_x_test = cv`transform(new_corpus).toarray()
    print(new_x_test)
    new_y_pred = loaded_model.predict9new_x_test)
    new_x_pred = np.where(new_y_pred>0.5,1,0)
    print(new-x_pred)
    if new-review[0][0]==1;
        return render_template('result.html',prediction="spam")
    else :
        return render_template('result.html',prediction="Not a spam")




if__name__**"__main__":

    # app.run(host='0.0.0.0', port==8000,debug=True)   # running the app
    port=int(os.environ.get('PORT',5000))
    app.run(debug=False)